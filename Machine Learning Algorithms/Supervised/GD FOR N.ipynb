{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(X, learning_rate, m, Y_true):\n",
    "    new_m = [0 for i in range(len(m))]\n",
    "    N = len(X)\n",
    "    # Caluculating Derivative of All The The Weights\n",
    "    for i in range(X.shape[1]):\n",
    "        # x is All The Columns so effectively the shape of x is (rows,colums)\n",
    "        x = X[:,i]\n",
    "        new_m[i] = -x*(Y_true - predict(X,m))\n",
    "     \n",
    "    new_m = np.array(new_m)\n",
    "    # Updating The Slope with Ascent \n",
    "    for i in range(X.shape[1]): \n",
    "        m[i] -= (learning_rate*np.mean(new_m[i]))\n",
    "    #print(m)    \n",
    "    return m\n",
    "\n",
    "def cost_gd(X,m,Y):\n",
    "    N = len(m)\n",
    "    sq_error = ((predict(X,m) - Y)**2).sum()\n",
    "    \n",
    "    # Return average squared error among predictions\n",
    "    return (1.0/(2*N))*sq_error\n",
    "\n",
    "def predict(X,m):\n",
    "    # Shape of X and m is (rows,14) and (14,1) repectively\n",
    "    return np.dot(X,m)\n",
    "\n",
    "def normalize(X):\n",
    "    if len(X.shape)==1:\n",
    "        x= X\n",
    "        x_mean = np.mean(x)\n",
    "        x_range = np.amax(x) - np.amin(x)\n",
    "        x = (x-x_mean)\n",
    "        x = x/x_range\n",
    "        X = x\n",
    "    elif len(X.shape)!=1:\n",
    "        for i in range(X.shape[1]):\n",
    "            x= X[:][i]\n",
    "            x_mean = np.mean(x)\n",
    "            x_range = np.amax(x) - np.amin(x)\n",
    "            x = (x-x_mean)\n",
    "            x = x/x_range\n",
    "            X[:][i] = x\n",
    "    return X\n",
    "\n",
    "def gd_runner(X, learning_rate, num_iterations, Y_true):\n",
    "    # Initialising The Coefficients having Shape (1, Column_length)\n",
    "    m = np.zeros((X.shape[1],))\n",
    "    print (\"Start: \", cost_gd(X, m, Y_true))\n",
    "    for i in range(num_iterations):\n",
    "        m = step_gradient(X, learning_rate, m, Y_true)\n",
    "    print (\"FINAL: \", cost_gd(X, m, Y_true))\n",
    "    return  m\n",
    "\n",
    "def run():\n",
    "    boston = datasets.load_boston()\n",
    "    # X is Numpy Array \n",
    "    X = boston.data\n",
    "    \n",
    "    # Adding Dummy Variables\n",
    "    Dummy = np.ones(shape=(len(X),1))\n",
    "    X = np.append(Dummy, X, axis=1)\n",
    "    Y_true = boston.target\n",
    "    \n",
    "    # Normalizing the Features and Target(Y_true)\n",
    "    X = normalize(X)\n",
    "    Y_true = normalize(Y_true)\n",
    "    \n",
    "\n",
    "    learning_rate = 0.000001\n",
    "    num_iterations = 100000\n",
    "    # Calling Step Gradient\n",
    "    final_m = gd_runner(X, learning_rate,num_iterations, Y_true)\n",
    "    print(final_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:  0.753373816843\n",
      "FINAL:  0.3111200366\n",
      "[ 0.00032    -0.00205453  0.00173378 -0.00129115  0.0006568   0.0001174\n",
      "  0.0064325   0.00177454 -0.00323081  0.00399369 -0.00016063 -0.00283287\n",
      "  0.00042126 -0.01762871]\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
